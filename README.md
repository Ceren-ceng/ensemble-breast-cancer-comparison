# ğŸ”¬ Ensemble Learning ile Meme Kanseri SÄ±nÄ±flandÄ±rmasÄ± (Random Forest, AdaBoost, XGBoost)

Bu projede, Breast Cancer Wisconsin (Diagnostic) veri seti ile Ã¼Ã§ farklÄ± ensemble Ã¶ÄŸrenme algoritmasÄ±nÄ±n (Random Forest, AdaBoost ve XGBoost) performansÄ±nÄ± aynÄ± veri seti Ã¼zerinde karÅŸÄ±laÅŸtÄ±rÄ±yoruz. TÃ¼m aÅŸamalar adÄ±m adÄ±m anlatÄ±lmÄ±ÅŸtÄ±r. Kod Ã¶rnekleri ve Ã§Ä±ktÄ±larla tam bir rehberdir.

---

## ğŸ“¢ Projenin AmacÄ±

- Ensemble (topluluk) Ã¶ÄŸrenme yÃ¶ntemlerini pratikte kÄ±yaslamak
- Hangi model hangi tÃ¼r veri ve problemde daha gÃ¼Ã§lÃ¼, avantaj ve dezavantajlarÄ± nelerdir gÃ¶rmek
- SÄ±fÄ±rdan Ã§alÄ±ÅŸma akÄ±ÅŸÄ±nÄ± gÃ¶rmek isteyenler iÃ§in aÃ§Ä±klamalÄ± ve gerÃ§ek Ã§Ä±ktÄ±lÄ± Ã¶rnek sunmak

---

## ğŸ“š Ensemble Learning Nedir?

Ensemble Learning, birden fazla makine Ã¶ÄŸrenmesi modelinin birleÅŸtirilerek (Ã§oÄŸunluk oyu, aÄŸÄ±rlÄ±klÄ± ortalama vs.) daha saÄŸlam, genellenebilir ve gÃ¼venilir sonuÃ§lar alÄ±nmasÄ±nÄ± amaÃ§lar. Tek baÅŸÄ±na zayÄ±f kalabilecek modeller bir araya gelince Ã§oÄŸu zaman daha baÅŸarÄ±lÄ± tahminler yapar.

**Ä°ki temel yaklaÅŸÄ±m vardÄ±r:**
- **Bagging (Bootstrap Aggregating):** AynÄ± algoritmadan birÃ§ok farklÄ± model rastgele Ã¶rneklerle eÄŸitilir (Ã¶r: Random Forest).
- **Boosting:** Modeller sÄ±ralÄ± ÅŸekilde eÄŸitilir, her biri Ã¶ncekinin hatalarÄ±nÄ± dÃ¼zeltmeye odaklanÄ±r (Ã¶r: AdaBoost, XGBoost).

---

## ğŸ·ï¸ KullanÄ±lan AlgoritmalarÄ±n Temel FarklarÄ±

### ğŸŒ² Random Forest (Bagging)
- Ã‡ok sayÄ±da karar aÄŸacÄ± oluÅŸturur
- Her bir aÄŸaÃ§ farklÄ± Ã¶rneklerle ve/veya farklÄ± Ã¶zelliklerle eÄŸitilir
- SonuÃ§, Ã§oÄŸunluk oyuyla verilir (klasik â€œdemokrasiâ€)
- AÅŸÄ±rÄ± Ã¶ÄŸrenmeye karÅŸÄ± direnÃ§lidir

### ğŸš€ AdaBoost (Boosting)
- ZayÄ±f Ã¶ÄŸrenicileri (genellikle tek katmanlÄ± karar aÄŸaÃ§larÄ±) sÄ±ralÄ± eÄŸitir
- Her yeni model, bir Ã¶ncekinin yanlÄ±ÅŸlarÄ±nÄ± dÃ¼zeltmeye Ã§alÄ±ÅŸÄ±r
- YanlÄ±ÅŸ tahmin edilen Ã¶rneklere daha Ã§ok aÄŸÄ±rlÄ±k verir

### âš¡ XGBoost (Boosting â€“ Advanced)
- Boosting yaklaÅŸÄ±mÄ±nÄ±n en geliÅŸmiÅŸ, hÄ±zlÄ± ve regularize edilmiÅŸ hali
- Eksik veriyle baÅŸa Ã§Ä±kabilir, paralel Ã§alÄ±ÅŸÄ±r, overfittingâ€™i azaltÄ±r
- Genellikle en iyi doÄŸruluk oranlarÄ±na ulaÅŸÄ±r

---

## ğŸ—‚ï¸ Veri Seti Ã–zeti

- **Kaynak:** Breast Cancer Wisconsin (Diagnostic)
- **Toplam GÃ¶zlem:** 569
- **Ã–zellik SayÄ±sÄ±:** 30 + 1 hedef sÃ¼tunu (`diagnosis`)
- **Hedef DeÄŸiÅŸken:** `diagnosis` (â€˜Mâ€™ = Malignant/KÃ¶tÃ¼ Huylu, â€˜Bâ€™ = Benign/Ä°yi Huylu)

### Ã–rnek SÃ¼tunlar:
- `radius_mean`, `texture_mean`, `perimeter_mean`, `area_mean`, `smoothness_mean` ...
- â€œUnnamed: 32â€ gibi alakasÄ±z/eksik sÃ¼tunlar silindi

---

## ğŸ§¹ Veri HazÄ±rlama AÅŸamalarÄ±

1. **YÃ¼kleme ve Temizlik:**
   - Gereksiz sÃ¼tunlar (Ã¶rn. id, Unnamed: 32) silindi.
   - `diagnosis` etiketi `0` (B) ve `1` (M) olarak encode edildi.
2. **Ã–znitelik ve Hedef AyrÄ±mÄ±:**
   - X = tÃ¼m Ã¶zellikler, y = diagnosis etiketi
3. **EÄŸitim/Test BÃ¶lmesi:**
   - %80 eÄŸitim, %20 test (stratify ile)
4. **Ã–lÃ§ekleme yapÄ±lmadÄ±** Ã§Ã¼nkÃ¼ aÄŸaÃ§ tabanlÄ± modeller buna ihtiyaÃ§ duymaz.

---

## ğŸ§  Model EÄŸitimi ve DeÄŸerlendirme

Her model iÃ§in:

- Model oluÅŸturuldu ve `.fit()` ile eÄŸitildi
- Test setinde `.predict()` ile tahminler yapÄ±ldÄ±
- Hata metrikleri (`accuracy`, `precision`, `recall`, `f1-score`) alÄ±ndÄ±
- Confusion matrix (karÄ±ÅŸÄ±klÄ±k matrisi) gÃ¶rseli Ã§izildi

---

## ğŸ§¾ KullanÄ±lan KÃ¼tÃ¼phaneler

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix


## ğŸ“Š SonuÃ§ Tablosu

| Model         | Accuracy | Precision | Recall | F1-score |
|---------------|----------|-----------|--------|----------|
| Random Forest | 0.9649   | 0.9722    | 0.9444 | 0.9581   |
| AdaBoost      | 0.9561   | 0.9722    | 0.9306 | 0.9510   |
| XGBoost       | 0.9737   | 0.9722    | 0.9583 | 0.9652   |

---

### ğŸ“ˆ Classification Reports

#### Random Forest

markdown
Kopyala
DÃ¼zenle
          precision    recall  f1-score   support

       0      0.97      0.98      0.98        71
       1      0.97      0.94      0.96        43

accuracy                          0.96       114
macro avg 0.97 0.96 0.96 114
weighted avg 0.97 0.96 0.96 114

shell
Kopyala
DÃ¼zenle

#### AdaBoost

markdown
Kopyala
DÃ¼zenle
          precision    recall  f1-score   support

       0      0.97      0.97      0.97        71
       1      0.97      0.93      0.95        43

accuracy                          0.96       114
macro avg 0.97 0.95 0.96 114
weighted avg 0.97 0.96 0.96 114

shell
Kopyala
DÃ¼zenle

#### XGBoost

markdown
Kopyala
DÃ¼zenle
          precision    recall  f1-score   support

       0      0.97      0.99      0.98        71
       1      0.97      0.96      0.97        43

accuracy                          0.97       114
macro avg 0.97 0.97 0.97 114
weighted avg 0.97 0.97 0.97 114

yaml
Kopyala
DÃ¼zenle

---

### ğŸ§‘â€ğŸ”¬ SonuÃ§larÄ±n YorumlanmasÄ± ve F1-Score DeÄŸerlendirmesi

- **XGBoost** en yÃ¼ksek accuracy ve en dengeli f1-score'u verdi.  
- **Random Forest** ve **AdaBoost** da Ã§ok yakÄ±n ve gÃ¼venilir sonuÃ§lar verdi.
- F1-score deÄŸerleri hem yanlÄ±ÅŸ pozitifleri hem de yanlÄ±ÅŸ negatifleri cezalandÄ±rdÄ±ÄŸÄ± iÃ§in saÄŸlÄ±k alanÄ± gibi kritik uygulamalarda en Ã¶nemli metriktir.
- Precision deÄŸerleri yÃ¼ksek: "kanser" dediÄŸi hastalarÄ±n neredeyse tamamÄ± gerÃ§ekten hasta.
- Recall yÃ¼ksek: Model, neredeyse tÃ¼m kanserli hastalarÄ± doÄŸru tespit ediyor.
- SonuÃ§: Bu veri seti iÃ§in en yÃ¼ksek genel baÅŸarÄ± XGBoost ile saÄŸlandÄ±. Random Forest ve AdaBoost da neredeyse aynÄ± baÅŸarÄ±da; Ã§ok bÃ¼yÃ¼k farklar yok.

---

ğŸ§‘â€ğŸ”¬ SonuÃ§larÄ±n Teknik DeÄŸerlendirmesi
Sadece accuracyâ€™ye bakmak yetersizdir. F1-score, recall ve precision saÄŸlÄ±k gibi kritik alanlarda Ã§ok daha Ã¶nemlidir.

F1-score yÃ¼ksekse, model hem yanlÄ±ÅŸ â€œhastaâ€ diyerek hem de â€œhastayÄ± gÃ¶zden kaÃ§Ä±rarakâ€ hata yapmÄ±yor demektir.

Precision dÃ¼ÅŸÃ¼kse, model saÄŸlÄ±klÄ± insana â€œkanserâ€ deme eÄŸiliminde (gereksiz korku, gereksiz test)

Recall dÃ¼ÅŸÃ¼kse, model kanser hastasÄ±nÄ± gÃ¶zden kaÃ§Ä±rÄ±yor (hayati risk!)

Klinik, saÄŸlÄ±k ve riskli alanlarda F1-score ve recall birincil metrik olarak izlenmelidir. En yÃ¼ksek f1-score ve recall, â€œen az Ã¶lÃ¼mcÃ¼l hataâ€ anlamÄ±na gelir.

ğŸ Son SÃ¶z: Hangi Model Ne Zaman?
Random Forest: HÄ±zlÄ±, dengeli ve genellikle default ayarlarÄ±yla bile iyi sonuÃ§

AdaBoost: Basit veride ve outlier azsa iyi Ã§alÄ±ÅŸÄ±r, noise fazlaysa dÃ¼ÅŸer

XGBoost: KarmaÅŸÄ±k veri, bÃ¼yÃ¼k set, yÃ¼ksek baÅŸarÄ± isteniyorsa Ã¶nerilir; ayar yapmak Ã¶nemlidir

ğŸ¤ KatkÄ± ve GeliÅŸtirme
Bu repo Ã¶ÄŸrenmek ve kendi veri setlerinizi test etmek iÃ§in uygundur. PR atabilirsiniz, parametrelerle oynayabilir, yeni metrik veya grafik ekleyebilirsiniz.



Keywords / Anahtar Kelimeler:

ensemble learning

random forest

adaboost

xgboost

breast cancer

cancer detection

classification

machine learning

boosting

bagging

sklearn

python

medical data

f1-score

accuracy

recall

precision

binary classification

data science

medical AI

diagnostic prediction

model comparison

confusion matrix

healthcare AI

-----------------------------------------

topluluk Ã¶ÄŸrenmesi

rastgele orman

adaboost

xgboost

meme kanseri

kanser tespiti

sÄ±nÄ±flandÄ±rma

makine Ã¶ÄŸrenmesi

hata metrikleri

doÄŸruluk

saÄŸlÄ±k verisi

ikili sÄ±nÄ±flandÄ±rma

model karÅŸÄ±laÅŸtÄ±rma

yapay zeka
